/opt/homebrew/Caskroom/miniconda/base/envs/z-image-mlx/lib/python3.12/site-packages/torch/amp/autocast_mode.py:270: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
Keyword arguments {'dtype': torch.float32} are not expected by ZImagePipeline and will be ignored.
Loading PyTorch Model...
Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]Loading pipeline components...:  20%|â–ˆâ–ˆ        | 1/5 [00:00<00:00,  9.18it/s]
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 65.91it/s]

Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s][A
Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:03,  1.86s/it][A
Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:04<00:02,  2.08s/it][ALoading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:04<00:00,  1.38s/it]
Loading pipeline components...:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:04<00:03,  1.60s/it]Loading pipeline components...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.12it/s]
Loading MLX Model...

Comparing Text Encoder...
PyTorch Text Encoder Hooks:
PT q_proj bias: False
PT Embeddings: Mean=-0.0002, Std=0.0196
PT Layer 0 Attn: Mean=-0.0012, Std=0.0561
PT Layer 0: Mean=-0.0001, Std=0.2052

MLX Text Encoder Forward:
MLX Embeddings: Mean=-0.0002, Std=0.0196
MLX Layer Attn: Mean=-0.0028, Std=0.0634
MLX Layer 0: Mean=0.0004, Std=0.2873
MLX Layer Attn: Mean=0.0027, Std=0.0811
MLX Layer Attn: Mean=0.0001, Std=0.0580
MLX Layer Attn: Mean=-0.0003, Std=0.0614
MLX Layer Attn: Mean=-0.0015, Std=0.0835
MLX Layer Attn: Mean=0.0027, Std=0.1106
MLX Layer Attn: Mean=-0.0014, Std=0.4406
MLX Layer Attn: Mean=0.0001, Std=0.1021
MLX Layer Attn: Mean=-0.0013, Std=0.1151
MLX Layer Attn: Mean=0.0010, Std=0.1060
MLX Layer Attn: Mean=0.0024, Std=0.1734
MLX Layer Attn: Mean=0.0018, Std=0.1317
MLX Layer Attn: Mean=-0.0019, Std=0.1254
MLX Layer Attn: Mean=0.0041, Std=0.1415
MLX Layer Attn: Mean=0.0001, Std=0.1403
MLX Layer Attn: Mean=-0.0018, Std=0.1868
MLX Layer Attn: Mean=-0.0018, Std=0.2740
MLX Layer Attn: Mean=0.0055, Std=0.6479
MLX Layer Attn: Mean=-0.0053, Std=0.1823
MLX Layer Attn: Mean=0.0077, Std=0.2710
MLX Layer Attn: Mean=-0.0058, Std=0.2805
MLX Layer Attn: Mean=0.0055, Std=0.2501
MLX Layer Attn: Mean=-0.0016, Std=0.4626
MLX Layer Attn: Mean=-0.0088, Std=0.3221
MLX Layer Attn: Mean=-0.0157, Std=0.4868
MLX Layer Attn: Mean=0.0058, Std=0.3283
MLX Layer Attn: Mean=0.0040, Std=0.3378
MLX Layer Attn: Mean=0.0123, Std=0.5717
MLX Layer Attn: Mean=-0.0006, Std=0.3776
MLX Layer Attn: Mean=-0.0160, Std=0.7695
MLX Layer Attn: Mean=0.0003, Std=0.7974
MLX Layer Attn: Mean=0.0113, Std=0.7132
MLX Layer Attn: Mean=0.0127, Std=0.9994
MLX Layer Attn: Mean=0.0167, Std=2.0245
MLX Layer Attn: Mean=0.0400, Std=2.2287
MLX Layer Attn: Mean=0.0069, Std=1.4674
--- Text Encoder Output ---
Max Diff: 92.435265
Mean Diff: 1.573066
âŒ MISMATCH (Threshold 0.01)

Comparing Transformer...
--- Transformer Output ---
Max Diff: 14.527372
Mean Diff: 2.070413
âŒ MISMATCH (Threshold 0.01)
